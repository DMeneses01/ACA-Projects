{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 50, 50, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 47,  64,  77],\n",
       "         [ 43,  57,  80],\n",
       "         [182, 206, 224],\n",
       "         ...,\n",
       "         [ 10,   8,   8],\n",
       "         [  9,   7,   7],\n",
       "         [  7,   5,   5]],\n",
       "\n",
       "        [[ 42,  59,  80],\n",
       "         [ 14,  22,  35],\n",
       "         [ 50,  62,  74],\n",
       "         ...,\n",
       "         [ 14,   9,  10],\n",
       "         [ 10,   5,   6],\n",
       "         [ 11,   6,   7]],\n",
       "\n",
       "        [[ 51,  68,  87],\n",
       "         [  0,   5,   9],\n",
       "         [  7,  14,  23],\n",
       "         ...,\n",
       "         [ 13,   8,  10],\n",
       "         [ 13,   8,   9],\n",
       "         [ 11,   6,   7]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 57,  63,  76],\n",
       "         [ 43,  55,  65],\n",
       "         [ 33,  45,  63],\n",
       "         ...,\n",
       "         [ 37,  36,  40],\n",
       "         [ 17,  12,  14],\n",
       "         [ 16,  11,  13]],\n",
       "\n",
       "        [[ 48,  58,  65],\n",
       "         [ 47,  53,  66],\n",
       "         [ 45,  53,  60],\n",
       "         ...,\n",
       "         [ 19,  21,  22],\n",
       "         [ 25,  20,  22],\n",
       "         [ 14,   9,  10]],\n",
       "\n",
       "        [[ 32,  40,  47],\n",
       "         [ 13,  19,  30],\n",
       "         [ 11,  17,  24],\n",
       "         ...,\n",
       "         [237, 239, 247],\n",
       "         [  0,   1,   2],\n",
       "         [ 16,  15,  17]]],\n",
       "\n",
       "\n",
       "       [[[172, 116,  81],\n",
       "         [169, 115,  80],\n",
       "         [171, 117,  82],\n",
       "         ...,\n",
       "         [167, 113,  80],\n",
       "         [170, 113,  81],\n",
       "         [168, 114,  81]],\n",
       "\n",
       "        [[177, 121,  86],\n",
       "         [175, 121,  86],\n",
       "         [173, 119,  84],\n",
       "         ...,\n",
       "         [169, 116,  83],\n",
       "         [170, 116,  81],\n",
       "         [163, 112,  79]],\n",
       "\n",
       "        [[174, 120,  85],\n",
       "         [174, 120,  85],\n",
       "         [173, 121,  85],\n",
       "         ...,\n",
       "         [169, 116,  83],\n",
       "         [166, 116,  80],\n",
       "         [182, 137, 104]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 35,  35,  35],\n",
       "         [ 30,  34,  35],\n",
       "         [ 40,  44,  45],\n",
       "         ...,\n",
       "         [184, 249, 255],\n",
       "         [178, 248, 255],\n",
       "         [118, 193, 219]],\n",
       "\n",
       "        [[ 42,  55,  57],\n",
       "         [ 33,  44,  48],\n",
       "         [ 52,  56,  57],\n",
       "         ...,\n",
       "         [130, 233, 255],\n",
       "         [114, 233, 254],\n",
       "         [ 98, 223, 244]],\n",
       "\n",
       "        [[ 59,  66,  63],\n",
       "         [ 41,  47,  46],\n",
       "         [ 51,  52,  50],\n",
       "         ...,\n",
       "         [ 94, 220, 249],\n",
       "         [ 95, 216, 248],\n",
       "         [ 90, 216, 251]]],\n",
       "\n",
       "\n",
       "       [[[203, 193, 186],\n",
       "         [201, 191, 184],\n",
       "         [200, 190, 183],\n",
       "         ...,\n",
       "         [204, 192, 186],\n",
       "         [204, 192, 186],\n",
       "         [207, 195, 189]],\n",
       "\n",
       "        [[204, 193, 189],\n",
       "         [203, 192, 188],\n",
       "         [200, 189, 185],\n",
       "         ...,\n",
       "         [206, 194, 190],\n",
       "         [206, 194, 190],\n",
       "         [207, 195, 191]],\n",
       "\n",
       "        [[203, 192, 188],\n",
       "         [204, 193, 189],\n",
       "         [203, 192, 188],\n",
       "         ...,\n",
       "         [205, 192, 190],\n",
       "         [205, 192, 190],\n",
       "         [206, 193, 191]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]],\n",
       "\n",
       "        [[  1,   1,   1],\n",
       "         [  0,   1,   0],\n",
       "         [  0,   1,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  1,   1,   1],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  4,   5,   3],\n",
       "         [ 11,  12,  10],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  0,   0,   0],\n",
       "         [  1,   1,   1]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[139, 140, 144],\n",
       "         [110, 103,  94],\n",
       "         [185, 163, 145],\n",
       "         ...,\n",
       "         [238, 255, 251],\n",
       "         [223, 236, 228],\n",
       "         [126, 130, 119]],\n",
       "\n",
       "        [[128, 129, 125],\n",
       "         [142, 130, 124],\n",
       "         [137, 120,  99],\n",
       "         ...,\n",
       "         [117, 186, 171],\n",
       "         [135, 177, 166],\n",
       "         [153, 228, 207]],\n",
       "\n",
       "        [[145, 140, 141],\n",
       "         [143, 130, 128],\n",
       "         [148, 133, 114],\n",
       "         ...,\n",
       "         [237, 246, 243],\n",
       "         [246, 245, 241],\n",
       "         [185, 209, 197]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[161, 160, 164],\n",
       "         [166, 169, 167],\n",
       "         [148, 150, 150],\n",
       "         ...,\n",
       "         [216, 211, 212],\n",
       "         [196, 196, 196],\n",
       "         [210, 210, 210]],\n",
       "\n",
       "        [[161, 165, 166],\n",
       "         [163, 165, 166],\n",
       "         [159, 161, 162],\n",
       "         ...,\n",
       "         [191, 189, 188],\n",
       "         [193, 188, 189],\n",
       "         [212, 207, 208]],\n",
       "\n",
       "        [[155, 159, 160],\n",
       "         [160, 162, 163],\n",
       "         [159, 161, 162],\n",
       "         ...,\n",
       "         [196, 194, 193],\n",
       "         [179, 176, 178],\n",
       "         [205, 202, 204]]],\n",
       "\n",
       "\n",
       "       [[[183, 152, 137],\n",
       "         [ 75,  26,  28],\n",
       "         [ 26,  10,   0],\n",
       "         ...,\n",
       "         [192, 172, 184],\n",
       "         [193, 172, 180],\n",
       "         [183, 159, 169]],\n",
       "\n",
       "        [[148, 102, 101],\n",
       "         [156, 128, 127],\n",
       "         [253, 230, 208],\n",
       "         ...,\n",
       "         [ 93,  71,  89],\n",
       "         [ 97,  80,  94],\n",
       "         [113,  94, 109]],\n",
       "\n",
       "        [[177, 142, 128],\n",
       "         [ 23,   1,   0],\n",
       "         [255, 249, 221],\n",
       "         ...,\n",
       "         [127, 103, 133],\n",
       "         [131, 104, 138],\n",
       "         [131, 104, 138]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[132,  87,  60],\n",
       "         [133,  92,  70],\n",
       "         [123,  89,  65],\n",
       "         ...,\n",
       "         [101,  61,  43],\n",
       "         [100,  58,  46],\n",
       "         [100,  58,  39]],\n",
       "\n",
       "        [[130,  84,  60],\n",
       "         [141,  96,  69],\n",
       "         [142,  98,  74],\n",
       "         ...,\n",
       "         [119,  74,  63],\n",
       "         [107,  65,  53],\n",
       "         [ 99,  54,  43]],\n",
       "\n",
       "        [[134,  92,  73],\n",
       "         [137,  94,  77],\n",
       "         [138,  96,  83],\n",
       "         ...,\n",
       "         [132,  86,  68],\n",
       "         [138,  94,  71],\n",
       "         [123,  77,  53]]],\n",
       "\n",
       "\n",
       "       [[[ 61,  68,  71],\n",
       "         [125, 131, 138],\n",
       "         [ 85,  91,  98],\n",
       "         ...,\n",
       "         [ 65,  60,  62],\n",
       "         [ 57,  51,  56],\n",
       "         [  7,   5,  11]],\n",
       "\n",
       "        [[ 82,  87,  90],\n",
       "         [ 65,  68,  76],\n",
       "         [102, 105, 113],\n",
       "         ...,\n",
       "         [ 83,  78,  87],\n",
       "         [ 60,  49,  51],\n",
       "         [ 37,  30,  35]],\n",
       "\n",
       "        [[168, 175, 178],\n",
       "         [ 72,  78,  85],\n",
       "         [162, 165, 173],\n",
       "         ...,\n",
       "         [ 67,  59,  69],\n",
       "         [253, 250, 252],\n",
       "         [ 23,  23,  29]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[107,  97,  90],\n",
       "         [131, 126, 123],\n",
       "         [132, 122, 115],\n",
       "         ...,\n",
       "         [ 83,  77,  72],\n",
       "         [ 93,  84,  80],\n",
       "         [105,  94,  90]],\n",
       "\n",
       "        [[115, 106,  97],\n",
       "         [122, 112, 105],\n",
       "         [128, 118, 111],\n",
       "         ...,\n",
       "         [ 45,  35,  35],\n",
       "         [ 63,  51,  47],\n",
       "         [ 74,  58,  52]],\n",
       "\n",
       "        [[129, 120, 111],\n",
       "         [129, 119, 112],\n",
       "         [124, 114, 107],\n",
       "         ...,\n",
       "         [123, 113, 126],\n",
       "         [ 97,  89,  82],\n",
       "         [ 61,  50,  42]]]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define path to the dataset\n",
    "PATH = \"C:/Users/emanu/Universidade/Mestrado/1_Ano/2_Semestre/ACA/Projeto/ACA-Project/AML-Project2/dataset\"\n",
    "\n",
    "# Read the CSV file containing the image paths and labels\n",
    "# Read the training set data\n",
    "train_data = np.load(os.path.join(PATH, \"trainX.npy\"))\n",
    "train_labels = np.load(os.path.join(PATH, \"trainy.npy\"), allow_pickle=True)\n",
    "\n",
    "test_data = np.load(os.path.join(PATH, \"testX.npy\"))\n",
    "\n",
    "print(train_data.shape)\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.Sequential([\n",
    "  layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_federated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\emanu\\Universidade\\Mestrado\\1_Ano\\2_Semestre\\ACA\\Projeto\\ACA-Project\\AML-Project2\\src\\cnn_synt.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/emanu/Universidade/Mestrado/1_Ano/2_Semestre/ACA/Projeto/ACA-Project/AML-Project2/src/cnn_synt.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_federated\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtff\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emanu/Universidade/Mestrado/1_Ano/2_Semestre/ACA/Projeto/ACA-Project/AML-Project2/src/cnn_synt.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m synt \u001b[39m=\u001b[39m tff\u001b[39m.\u001b[39msimulation\u001b[39m.\u001b[39mFromTensorSlicesClientData(train_data)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_federated'"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "# Add the image to a batch.\n",
    "image = tf.expand_dims(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  # Add the preprocessing layers you created earlier.\n",
    "  rescale,\n",
    "  data_augmentation,\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  # Rest of your model.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Resize and rescale all datasets.\n",
    "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
    "              num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_ds = prepare(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 11, 11, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366,054\n",
      "Trainable params: 366,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation='relu', input_shape=(50, 50, 3)))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Conv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_one_hot = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "135/135 [==============================] - 8s 51ms/step - loss: 1.2614 - accuracy: 0.4684 - val_loss: 0.9830 - val_accuracy: 0.5990\n",
      "Epoch 2/40\n",
      "135/135 [==============================] - 7s 50ms/step - loss: 0.9468 - accuracy: 0.6296 - val_loss: 0.9055 - val_accuracy: 0.6302\n",
      "Epoch 3/40\n",
      "135/135 [==============================] - 7s 49ms/step - loss: 0.8219 - accuracy: 0.6906 - val_loss: 0.8622 - val_accuracy: 0.6906\n",
      "Epoch 4/40\n",
      "135/135 [==============================] - 7s 50ms/step - loss: 0.7391 - accuracy: 0.7266 - val_loss: 0.7227 - val_accuracy: 0.7500\n",
      "Epoch 5/40\n",
      "135/135 [==============================] - 7s 51ms/step - loss: 0.6390 - accuracy: 0.7685 - val_loss: 0.6905 - val_accuracy: 0.7615\n",
      "Epoch 6/40\n",
      "135/135 [==============================] - 7s 53ms/step - loss: 0.5937 - accuracy: 0.7853 - val_loss: 0.6486 - val_accuracy: 0.7719\n",
      "Epoch 7/40\n",
      "135/135 [==============================] - 7s 54ms/step - loss: 0.5589 - accuracy: 0.7991 - val_loss: 0.6188 - val_accuracy: 0.8031\n",
      "Epoch 8/40\n",
      "135/135 [==============================] - 7s 55ms/step - loss: 0.5328 - accuracy: 0.8065 - val_loss: 0.6701 - val_accuracy: 0.7490\n",
      "Epoch 9/40\n",
      "135/135 [==============================] - 7s 55ms/step - loss: 0.5217 - accuracy: 0.8102 - val_loss: 0.6476 - val_accuracy: 0.7708\n",
      "Epoch 10/40\n",
      "135/135 [==============================] - 8s 56ms/step - loss: 0.4586 - accuracy: 0.8328 - val_loss: 0.6069 - val_accuracy: 0.8010\n",
      "Epoch 11/40\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.4514 - accuracy: 0.8338 - val_loss: 0.5916 - val_accuracy: 0.8062\n",
      "Epoch 12/40\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.4094 - accuracy: 0.8558 - val_loss: 0.6279 - val_accuracy: 0.7958\n",
      "Epoch 13/40\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3860 - accuracy: 0.8648 - val_loss: 0.6470 - val_accuracy: 0.7760\n",
      "Epoch 14/40\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3487 - accuracy: 0.8718 - val_loss: 0.6246 - val_accuracy: 0.8115\n",
      "Epoch 15/40\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3146 - accuracy: 0.8863 - val_loss: 0.6453 - val_accuracy: 0.8010\n",
      "Epoch 16/40\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.2958 - accuracy: 0.8931 - val_loss: 0.7230 - val_accuracy: 0.7844\n",
      "Epoch 17/40\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.2745 - accuracy: 0.8999 - val_loss: 0.6886 - val_accuracy: 0.7792\n",
      "Epoch 18/40\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.2607 - accuracy: 0.9064 - val_loss: 0.7118 - val_accuracy: 0.7969\n",
      "Epoch 19/40\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.2345 - accuracy: 0.9175 - val_loss: 0.7631 - val_accuracy: 0.7885\n",
      "Epoch 20/40\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.2275 - accuracy: 0.9159 - val_loss: 0.8247 - val_accuracy: 0.7667\n",
      "Epoch 21/40\n",
      "135/135 [==============================] - 8s 60ms/step - loss: 0.2062 - accuracy: 0.9259 - val_loss: 0.7761 - val_accuracy: 0.7927\n",
      "Epoch 22/40\n",
      "135/135 [==============================] - 8s 60ms/step - loss: 0.1686 - accuracy: 0.9403 - val_loss: 0.8110 - val_accuracy: 0.8000\n",
      "Epoch 23/40\n",
      "135/135 [==============================] - 8s 62ms/step - loss: 0.1533 - accuracy: 0.9472 - val_loss: 0.8811 - val_accuracy: 0.7812\n",
      "Epoch 24/40\n",
      "135/135 [==============================] - 12s 85ms/step - loss: 0.1487 - accuracy: 0.9480 - val_loss: 0.9585 - val_accuracy: 0.7625\n",
      "Epoch 25/40\n",
      "135/135 [==============================] - 12s 87ms/step - loss: 0.1530 - accuracy: 0.9448 - val_loss: 0.8642 - val_accuracy: 0.7833\n",
      "Epoch 26/40\n",
      "135/135 [==============================] - 11s 84ms/step - loss: 0.1146 - accuracy: 0.9603 - val_loss: 0.9427 - val_accuracy: 0.7937\n",
      "Epoch 27/40\n",
      "135/135 [==============================] - 11s 85ms/step - loss: 0.1100 - accuracy: 0.9606 - val_loss: 1.0403 - val_accuracy: 0.7844\n",
      "Epoch 28/40\n",
      "135/135 [==============================] - 8s 61ms/step - loss: 0.0968 - accuracy: 0.9677 - val_loss: 1.0472 - val_accuracy: 0.7958\n",
      "Epoch 29/40\n",
      "135/135 [==============================] - 8s 60ms/step - loss: 0.1052 - accuracy: 0.9633 - val_loss: 1.1170 - val_accuracy: 0.7646\n",
      "Epoch 30/40\n",
      "135/135 [==============================] - 8s 61ms/step - loss: 0.1208 - accuracy: 0.9587 - val_loss: 1.0476 - val_accuracy: 0.7823\n",
      "Epoch 31/40\n",
      "135/135 [==============================] - 8s 61ms/step - loss: 0.1078 - accuracy: 0.9634 - val_loss: 1.0450 - val_accuracy: 0.7875\n",
      "Epoch 32/40\n",
      "135/135 [==============================] - 8s 62ms/step - loss: 0.0861 - accuracy: 0.9707 - val_loss: 1.0556 - val_accuracy: 0.7812\n",
      "Epoch 33/40\n",
      "135/135 [==============================] - 8s 62ms/step - loss: 0.0956 - accuracy: 0.9668 - val_loss: 1.1091 - val_accuracy: 0.7875\n",
      "Epoch 34/40\n",
      "135/135 [==============================] - 8s 62ms/step - loss: 0.0726 - accuracy: 0.9755 - val_loss: 1.1090 - val_accuracy: 0.7771\n",
      "Epoch 35/40\n",
      "135/135 [==============================] - 8s 62ms/step - loss: 0.0829 - accuracy: 0.9729 - val_loss: 1.1110 - val_accuracy: 0.7688\n",
      "Epoch 36/40\n",
      "135/135 [==============================] - 8s 62ms/step - loss: 0.0757 - accuracy: 0.9752 - val_loss: 1.1691 - val_accuracy: 0.7740\n",
      "Epoch 37/40\n",
      "135/135 [==============================] - 8s 63ms/step - loss: 0.0705 - accuracy: 0.9791 - val_loss: 1.3094 - val_accuracy: 0.7698\n",
      "Epoch 38/40\n",
      "135/135 [==============================] - 8s 63ms/step - loss: 0.0628 - accuracy: 0.9807 - val_loss: 1.2437 - val_accuracy: 0.7802\n",
      "Epoch 39/40\n",
      "135/135 [==============================] - 8s 63ms/step - loss: 0.0656 - accuracy: 0.9785 - val_loss: 1.1758 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "135/135 [==============================] - 8s 63ms/step - loss: 0.0506 - accuracy: 0.9839 - val_loss: 1.3645 - val_accuracy: 0.7844\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=train_Y_one_hot,\n",
    "    batch_size=64,\n",
    "    epochs=40,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 13ms/step - loss: 0.9522 - accuracy: 0.8258\n",
      "75/75 [==============================] - 1s 12ms/step\n",
      "[1 0 3 ... 1 1 5]\n",
      "[1 0 3 ... 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       400\n",
      "           1       0.91      0.95      0.93       400\n",
      "           2       0.81      0.80      0.80       400\n",
      "           3       0.80      0.83      0.82       400\n",
      "           4       0.85      0.83      0.84       400\n",
      "           5       0.78      0.81      0.79       400\n",
      "\n",
      "    accuracy                           0.83      2400\n",
      "   macro avg       0.83      0.83      0.83      2400\n",
      "weighted avg       0.83      0.83      0.83      2400\n",
      "\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "test_Y_one_hot = keras.utils.to_categorical(y_test)\n",
    "test_Y_one_hot = tf.convert_to_tensor(test_Y_one_hot, dtype=tf.float32)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.evaluate(X_test, test_Y_one_hot)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "test_Y_one_hot = np.argmax(test_Y_one_hot, axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(test_Y_one_hot)\n",
    "\n",
    "print(classification_report(test_Y_one_hot, pred, zero_division=0))\n",
    "print('=========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(PATH, \"test_intel-image-classification-csvdata-kaggle.csv\"))\n",
    "\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "test_data = tf.convert_to_tensor(test_data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 2s 12ms/step\n",
      "      number  class\n",
      "0          0      1\n",
      "1          1      0\n",
      "2          2      0\n",
      "3          3      0\n",
      "4          4      0\n",
      "...      ...    ...\n",
      "5046    5046      5\n",
      "5047    5047      5\n",
      "5048    5048      5\n",
      "5049    5049      5\n",
      "5050    5050      5\n",
      "\n",
      "[5051 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "predict_test = np.argmax(preds, axis=1)\n",
    "\n",
    "submission = pd.DataFrame({'number': test_df['number'], 'class': predict_test})\n",
    "print(submission)\n",
    "submission.to_csv('submission_cnn_oneHot_01val_40e_64b_maxp_025do_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
