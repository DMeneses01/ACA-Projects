{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define path to the dataset\n",
    "PATH = \"C:/Users/emanu/Universidade/Mestrado/1_Ano/2_Semestre/ACA/Projeto/ACA-Project/AML-Project2/dataset\"\n",
    "\n",
    "# Read the CSV file containing the image paths and labels\n",
    "train_df = pd.read_csv(os.path.join(PATH, \"train_intel-image-classification-csvdata.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(PATH, \"test_intel-image-classification-csvdata-kaggle.csv\"))\n",
    "\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainv = train_df['class']\n",
    "X_trainv = train_df.drop(columns=['class', 'filename', 'number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X_trainv, y_trainv, train_size=0.6, random_state=42, stratify=y_trainv)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42, stratify=y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, der=False):\n",
    "    if (der==True) : #derivative \n",
    "        f = 1/(1+ np.exp(-x))*(1-1/(1+ np.exp(- x)))\n",
    "    else : # sigmoid\n",
    "        f = 1/(1+ np.exp(-x))\n",
    "    return f\n",
    "\n",
    "# We may employ the Rectifier Linear Unit (ReLU)\n",
    "def relu(x, der=False):\n",
    "    if (der == True): # the derivative of the ReLU is the Heaviside Theta\n",
    "        f = np.heaviside(x, 1)\n",
    "    else :\n",
    "        f = np.maximum(x, 0)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, number_of_inputs, n_targets, n_hidden, number_of_iterations=1000, learning_rate=0.01, output_type='linear'):\n",
    "        # Netowrk Parameters\n",
    "        self.number_of_iterations = number_of_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        self.number_of_outputs = n_targets\n",
    "        self.n_hidden = n_hidden\n",
    "        self.output_type = output_type\n",
    "\n",
    "        #Weight Initialisation\n",
    "        self.weights1 = (np.random.rand(self.number_of_inputs+1,self.n_hidden)-0.5)*2/np.sqrt(self.number_of_inputs)\n",
    "        self.weights2 = (np.random.rand(self.n_hidden+1,self.number_of_outputs)-0.5)*2/np.sqrt(self.n_hidden)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = np.concatenate((inputs,np.ones((inputs.shape[0],1))),axis=1)\n",
    "        return self.forward_propagation(inputs)\n",
    "    \n",
    "    def forward_propagation(self, inputs):\n",
    "        ## YOUR CODE HERE ##\n",
    "        # From input to hidden layer\n",
    "        self.hidden = np.dot(inputs, self.weights1);\n",
    "        \n",
    "        # Activation function. You can start with the RELU, and then include other options later. \n",
    "        # Do not forget that you need to use the right derivative when updating the weights\n",
    "        self.hidden = relu(self.hidden)\n",
    "        \n",
    "        # Add the bias in the hidden layer\n",
    "        self.hidden = np.concatenate((self.hidden,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "\n",
    "        # From hidden layer to output\n",
    "        outputs = np.dot(self.hidden,self.weights2);\n",
    "        \n",
    "        \n",
    "        # Output with different activation functions\n",
    "        if self.output_type == 'linear':\n",
    "            return outputs\n",
    "        elif self.output_type == 'logistic':\n",
    "            return sigmoid(outputs)\n",
    "        elif self.output_type == 'relu':\n",
    "            return relu(outputs)\n",
    "        \n",
    "\n",
    "    def train(self, training_inputs, targets):\n",
    "        #Add the Bias to the Input Matrix as as a fixed input.\n",
    "        training_inputs = np.concatenate((training_inputs,np.ones((training_inputs.shape[0],1))),axis=1)\n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))\n",
    "        \n",
    "        for n in range(self.number_of_iterations):\n",
    "            ## YOUR CODE HERE ##\n",
    "            #Compute the prediction based on the training inputs\n",
    "            self.predictions = self.forward_propagation(training_inputs)\n",
    "\n",
    "            #Compute the Error\n",
    "            error = 0.5 * np.sum((targets - self.predictions)**2)\n",
    "            if error < 0.1:\n",
    "                break\n",
    "\n",
    "            if n % 1000 == 0:\n",
    "                print(\"Iteration %d, Loss: %f\" % (n, error))\n",
    "\n",
    "            #Update the weights backwards\n",
    "            # Different types of output neurons\n",
    "            if self.output_type == 'linear':\n",
    "                deltao = (self.predictions-targets) / training_inputs.shape[0]\n",
    "            elif self.output_type == 'logistic':\n",
    "                deltao = (self.predictions-targets) * sigmoid(self.predictions, der=True)\n",
    "            elif self.output_type == 'relu':\n",
    "                deltao = (self.predictions-targets) * relu(self.predictions, der=True)\n",
    "            \n",
    "            deltah = relu(self.hidden, der=True) * (np.dot(deltao, np.transpose(self.weights2)))\n",
    "            \n",
    "            updatew2 = self.learning_rate * (np.dot(np.transpose(self.hidden),deltao))\n",
    "            \n",
    "            updatew1 = self.learning_rate * (np.dot(np.transpose(training_inputs),deltah[:,:-1]))\n",
    "            \n",
    "            self.weights1 = self.weights1 - updatew1\n",
    "            self.weights2 = self.weights2 - updatew2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six = np.zeros((X_train.shape[0], 6))\n",
    "six[np.where(y_train == 0),0] = 1\n",
    "six[np.where(y_train == 1),1] = 1\n",
    "six[np.where(y_train == 2),2] = 1\n",
    "six[np.where(y_train == 3),3] = 1\n",
    "six[np.where(y_train == 4),4] = 1\n",
    "six[np.where(y_train == 5),5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = MultiLayerPerceptron(X_train.shape[1], 6, 30, number_of_iterations=10000, output_type='logistic', learning_rate = 0.001)\n",
    "an.train(X_train, six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,  mean_squared_error, r2_score\n",
    "\n",
    "train_predictions = np.argmax(an.predict(X_train), axis=1)\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_train, train_predictions))\n",
    "print(\"Accuracy: %.2f %%\" % (accuracy_score(y_train, train_predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.argmax(an.predict(X_test), axis=1)\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Accuracy: %.2f %%\" % (accuracy_score(y_test, test_predictions) * 100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
